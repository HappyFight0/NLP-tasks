{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99aa7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb59c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/69937/pg69937.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2920342",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0797021",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2905bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c3f6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'Shakespeare', \"'s\", 'Roman', 'Plays', 'and', 'Their', 'Background', ',', 'by', 'Mungo', 'William', 'MacCallum', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'Shakespeare', \"'s\", 'Roman', 'Plays', 'and', 'Their', 'Background', 'Author', ':', 'Mungo', 'William', 'MacCallum', 'Release', 'Date', ':', 'February', '3', ',', '2023', '[', 'eBook', '#', '69937', ']', 'Language', ':', 'English', 'Produced', 'by', ':', 'Tim', 'Lindell', 'and', 'the', 'Online', 'Distributed', 'Proofreading', 'Team', 'at', 'https', ':', '//www.pgdp.net', '(', 'This', 'file', 'was', 'produced', 'from', 'images', 'generously', 'made', 'available', 'by', 'The', 'Internet', 'Archive', ')', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'SHAKESPEARE', \"'S\", 'ROMAN', 'PLAYS', 'AND', 'THEIR', 'BACKGROUND', '*', '*', '*', 'Transcriber', '’', 's', 'Notes', ':', 'Underscores', '“', '_', '”', 'before', 'and', 'after', 'a', 'word', 'or', 'phrase', 'indicate', '_italics_']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90768d0",
   "metadata": {},
   "source": [
    "clean this thing\n",
    "tokenize\n",
    "pos \n",
    "sentence tokenizer\n",
    "then using this perform someting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f95aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beautifulSoup\n",
    "#preprocessing - RE to clean any html \n",
    "#pos tagging\n",
    "#!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e1ac6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'revolut'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "porter.stem('happiness')\n",
    "porter.stem('joyous')\n",
    "porter.stem('cacti')\n",
    "porter.stem('singing')\n",
    "porter.stem('revolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6de98f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crack'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "lancaster.stem(\"Happiness\")\n",
    "lancaster.stem(\"cacti\")\n",
    "lancaster.stem(\"revolution\")\n",
    "lancaster.stem(\"cracked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "021afca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clingy'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RegexpStemmer\n",
    "regexp = RegexpStemmer('ing$')\n",
    "regexp.stem('singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e29b54fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crankenhous'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('german')\n",
    "snowball.stem('crankenhouse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65896789",
   "metadata": {},
   "outputs": [],
   "source": [
    "add for loop to stem an entire document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86b71333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿the\n",
      "project\n",
      "gutenberg\n",
      "ebook\n",
      "of\n",
      "shakespear\n",
      "'s\n",
      "rom\n",
      "play\n",
      "and\n",
      "their\n",
      "background\n",
      ",\n",
      "by\n",
      "mungo\n",
      "william\n",
      "maccall\n",
      "thi\n",
      "ebook\n",
      "is\n",
      "for\n",
      "the\n",
      "us\n",
      "of\n",
      "anyon\n",
      "anywh\n",
      "in\n",
      "the\n",
      "unit\n",
      "stat\n",
      "and\n",
      "most\n",
      "oth\n",
      "part\n",
      "of\n",
      "the\n",
      "world\n",
      "at\n",
      "no\n",
      "cost\n",
      "and\n",
      "with\n",
      "almost\n",
      "no\n",
      "restrict\n",
      "whatsoev\n",
      ".\n",
      "you\n",
      "may\n",
      "cop\n",
      "it\n",
      ",\n",
      "giv\n",
      "it\n",
      "away\n",
      "or\n",
      "re-us\n",
      "it\n",
      "und\n",
      "the\n",
      "term\n",
      "of\n",
      "the\n",
      "project\n",
      "gutenberg\n",
      "licens\n",
      "includ\n",
      "with\n",
      "thi\n",
      "ebook\n",
      "or\n",
      "onlin\n",
      "at\n",
      "www.gutenberg.org\n",
      ".\n",
      "if\n",
      "you\n",
      "ar\n",
      "not\n",
      "loc\n",
      "in\n",
      "the\n",
      "unit\n",
      "stat\n",
      ",\n",
      "you\n",
      "wil\n",
      "hav\n",
      "to\n",
      "check\n",
      "the\n",
      "law\n",
      "of\n",
      "the\n",
      "country\n",
      "wher\n",
      "you\n",
      "ar\n",
      "loc\n",
      "bef\n",
      "us\n",
      "thi\n",
      "ebook\n",
      ".\n",
      "titl\n",
      ":\n",
      "shakespear\n",
      "'s\n",
      "rom\n",
      "play\n",
      "and\n",
      "their\n",
      "background\n",
      "auth\n",
      ":\n",
      "mungo\n",
      "william\n",
      "maccall\n",
      "releas\n",
      "dat\n",
      ":\n",
      "febru\n",
      "3\n",
      ",\n",
      "2023\n",
      "[\n",
      "ebook\n",
      "#\n",
      "69937\n",
      "]\n",
      "langu\n",
      ":\n",
      "engl\n",
      "produc\n",
      "by\n",
      ":\n",
      "tim\n",
      "lindel\n",
      "and\n",
      "the\n",
      "onlin\n",
      "distribut\n",
      "proofread\n",
      "team\n",
      "at\n",
      "https\n",
      ":\n",
      "//www.pgdp.net\n",
      "(\n",
      "thi\n",
      "fil\n",
      "was\n",
      "produc\n",
      "from\n",
      "im\n",
      "gen\n",
      "mad\n",
      "avail\n",
      "by\n",
      "the\n",
      "internet\n",
      "arch\n",
      ")\n",
      "*\n",
      "*\n",
      "*\n",
      "start\n",
      "of\n",
      "the\n",
      "project\n",
      "gutenberg\n",
      "ebook\n",
      "shakespear\n",
      "'s\n",
      "rom\n",
      "play\n",
      "and\n",
      "their\n",
      "background\n",
      "*\n",
      "*\n",
      "*\n",
      "transcrib\n",
      "’\n",
      "s\n",
      "not\n",
      ":\n",
      "undersc\n",
      "“\n",
      "_\n",
      "”\n",
      "bef\n",
      "and\n",
      "aft\n",
      "a\n",
      "word\n",
      "or\n",
      "phrase\n",
      "ind\n",
      "_italics_\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "for x in tokens[:200]:\n",
    "    print(lancaster.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5a78a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thi',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyon',\n",
       " 'anywher',\n",
       " 'in',\n",
       " 'the',\n",
       " 'unit',\n",
       " 'state',\n",
       " 'and',\n",
       " 'most',\n",
       " 'other',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrict',\n",
       " 'whatsoever.',\n",
       " 'you',\n",
       " 'may',\n",
       " 'copi',\n",
       " 'it,',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-us',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'term',\n",
       " 'of',\n",
       " 'the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'licens',\n",
       " 'includ',\n",
       " 'with',\n",
       " 'thi',\n",
       " 'ebook',\n",
       " 'or',\n",
       " 'onlin',\n",
       " 'at',\n",
       " 'www.gutenberg.org.',\n",
       " 'if',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'locat',\n",
       " 'in',\n",
       " 'the',\n",
       " 'unit',\n",
       " 'states,',\n",
       " 'you',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'law',\n",
       " 'of',\n",
       " 'the',\n",
       " 'countri',\n",
       " 'where',\n",
       " 'you',\n",
       " 'are',\n",
       " 'locat',\n",
       " 'befor',\n",
       " 'use',\n",
       " 'thi',\n",
       " 'ebook.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "text = \"This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook.\"\n",
    "s = [porter.stem(token) for token in text.split()]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6436c918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cactus'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma= WordNetLemmatizer()\n",
    "lemma.lemmatize('cacti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4d3c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "best\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize(\"am\", pos=\"v\"))\n",
    "print(lemma.lemmatize(\"best\", pos=\"v\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
